---
title: "Data Validation in Excel and R"
author: "Eric R. Scott"
date: '2022-08-24'
---

# Load packages

```{r}
library(tidyverse)
library(visdat)
library(pointblank)
library(readxl)
library(skimr)
```

# Learning Objectives

-   Understand best practices for entering data and fixing errors in data
-   Use Excel data validation tools to prevent data entry errors
-   Compare data entered by two people in R to check for data entry mistakes
-   Explore data summaries to check for errors
-   Get the gist of how you can use the `pointblank` package to perform data validation checks


# Data Validation Tools in Excel

-   Select a column (or cells) and choose `Data > Validation â€¦` from the menu
-   Use "list" to restrict to specific values for categorical data
-   Use "whole number" for count data
-   Use "date" to restrict date ranges

To stop Excel from converting entries to dates:

1.  Explicitly set all column types to numeric, text, date, etc.
2.  Make sure no columns are set to "general"

# Double-entry Method

-   Two people enter the same data, then compare programatically.
-   In the `data` folder, there are two versions of a dataset---one entered by Eric and one entered by Jessica.

```{r}
eric <- read_csv("data/tea_eric.csv")
jessica <- read_csv("data/tea_jessica.csv")
```

## Compare visually with `visdat`

We can compare them a couple of ways.
First, we can compare them visually using the `visdat` package.
This only works if the two datasets are the same dimensions.

```{r}
vis_compare(eric, jessica)
```

## Compare with `dplyr::anti_join()`

First add row numbers to make it easier to find mistakes in Excel.

```{r}
# Optional: add rownumbers that match Excel (headers are row 1)
eric    <- eric    %>% mutate(row = 2:(n()+1), .before = date)
jessica <- jessica %>% mutate(row = 2:(n()+1), .before = date)
```

`anti_join()` takes two data frames and returns only rows that differ between them.

```{r}
#values in `eric` that are different in `jessica`
anti_join(eric, jessica)
#values in `jessica` that are different in `eric`
anti_join(jessica, eric)
```

What errors can you spot?


```{r}
#after fixing data-entry errors, we get `data_resolved.csv`
tea <- read_csv("data/tea_resolved.csv")
```

# Explore data summaries

-   You can't check for errors if you don't get to know your data!
-   Use `skimr::skim()` to get a nicely formatted summary
-   Look for number of unique values for categorical variables
-   Look for long tails or strange patterns in mini-histograms for numeric variables

```{r}
skimr::skim(tea)
```

Or get a more detailed breakdown by running `skim()` on a grouped data frame:

```{r}
#hint: use `group_by()` before passing data to `skim()`
```

## Explore data visually

-   `visdat::vis_guess()` can help spot inconsistencies

```{r}
visdat::vis_guess(tea)
```

Try intentionally introducing different kinds of mistakes to see if `vis_guess()` can spot them:

- change a `plant_id` to a character value
- change a `plot` to a number
- change a value of `shts` to a decimal
- change a value of `flwr` to "TRUE"

```{r}
tea_messed_up <- tea

# mess up the data.  E.g.:
tea_messed_up$plant_id[25] <- "plant1"




vis_guess(tea_messed_up)
```


# Data validation pipelines with `pointblank`

https://rich-iannone.github.io/pointblank

```{r}
library(pointblank)
```


## `pointblank` demo

1.  Decide on "action levels". Can set a number or fraction of rows as a threshold for a warning or error

```{r}
al <- action_levels(warn_at = 1, stop_at = .05)
al
```

2.  Create agent

```{r}
agent <- 
  create_agent(
    tbl = tea, #our data example from before
    actions = al
  )
```

3.  Specify validation conditions

    -   Basic checks on column types with `col_is_*()` functions
    -   Check column values with `col_vals_*()` functions
    -   Check rows (e.g. duplicate rows) with `rows_*()` functions

```{r}
agent_informed <- 
  agent %>% 
  col_is_date(date) %>% # should be a date
  col_vals_in_set(field, c("A", "B")) %>%
  # all shoot_ columns should be less than 15 cm (NAs allowed)
  col_vals_lt(starts_with("shoot_"), 15, na_pass = TRUE)
  

```

4.  Interrogate!

```{r}
agent_informed %>% interrogate()
```

## Add validation steps

Try using `col_is*()`, `col_vals*()`, and `rows_*()` functions to add the following validation steps:

  - check that the `hoppers`, `shts_*`, and `leaves` columns are numeric
  - check that `counter` should be "W", "G", or "E" only (use `col_vals_in_set()`)
  - check that `plant_id` should be in 1:20 (use `col_vals_between()`)
  - check that there are no missing values for `date`, `field`, `time`, and `plant_id` (use `col_vals_not_null()`)


## Flexible validations

If a validation function you need doesn't exist, you can use `col_vals_expr()`

E.g. let's add a validation that height is measured to the nearest cm.

```{r}
agent_informed  %>%  
  col_vals_expr(~ hoppers %% 1 == 0) %>%  #modulo operation (%%) returns remainder
  interrogate()
```

Use the same pattern to check that values in the `leaves` column are integers

```{r}
agent_informed %>% 
  #add your validation steps
  interrogate()
```

## Create new columns to test on the fly

"preconditions" let you manipulate the data before a check is run within a single validation step.

E.g. run a check on hoppers/leaves

```{r}
agent_informed %>% 
  col_vals_lt(
    columns = hoppers_per_leaf, #doesn't exist yet 
    value = 0.5, #expect less than 0.5
    na_pass = TRUE, #allow NAs
    # creates a new column on the fly:
    preconditions = function(df) mutate(df, hoppers_per_leaf = hoppers / leaves)
    ) %>% 
  interrogate()
```

Try using a similar pattern to write a validation for the standard deviation among `shts_*` 

```{r}
agent_informed %>% 
  #add your validation steps
  interrogate()
```

